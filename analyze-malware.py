#!/usr/bin/env python3
"""
Advanced Malware Analysis Script
Runs comprehensive security analysis on suspicious code in a sandboxed environment
"""

import os
import sys
import json
import hashlib
import subprocess
import time
from datetime import datetime
from pathlib import Path
import psutil
import requests
import yara
from capstone import Cs, CS_ARCH_X86, CS_MODE_64
import pefile
from typing import Dict, List, Any, Optional
import logging

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class MalwareAnalyzer:
    def __init__(self, target_file: str):
        self.target_file = Path(target_file)
        self.analysis_results = {
            'file_info': {},
            'static_analysis': {},
            'dynamic_analysis': {},
            'behavioral_analysis': {},
            'network_analysis': {},
            'file_analysis': {},
            'risk_assessment': {},
            'recommendations': []
        }
        self.start_time = datetime.now()

    def calculate_file_hash(self) -> Dict[str, str]:
        """Calculate various file hashes"""
        hashes = {}
        with open(self.target_file, 'rb') as f:
            data = f.read()
            hashes['md5'] = hashlib.md5(data).hexdigest()
            hashes['sha1'] = hashlib.sha1(data).hexdigest()
            hashes['sha256'] = hashlib.sha256(data).hexdigest()
        return hashes

    def analyze_file_info(self) -> Dict[str, Any]:
        """Gather basic file information"""
        stat = self.target_file.stat()
        return {
            'filename': self.target_file.name,
            'path': str(self.target_file),
            'size': stat.st_size,
            'modified': datetime.fromtimestamp(stat.st_mtime).isoformat(),
            'permissions': oct(stat.st_mode)[-3:],
            'hashes': self.calculate_file_hash()
        }

    def static_code_analysis(self) -> Dict[str, Any]:
        """Perform static analysis on Python code"""
        results = {
            'suspicious_imports': [],
            'dangerous_functions': [],
            'hardcoded_secrets': [],
            'code_patterns': [],
            'complexity_score': 0
        }

        try:
            with open(self.target_file, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read()

            # Analyze imports
            dangerous_imports = [
                'subprocess', 'os.system', 'os.popen', 'os.exec',
                'socket', 'urllib', 'requests', 'http.client',
                'ftplib', 'smtplib', 'telnetlib', 'ssl',
                'cryptography', 'hashlib', 'secrets'
            ]

            lines = content.split('\n')
            for line in lines:
                line = line.strip()
                if line.startswith('import ') or line.startswith('from '):
                    for dangerous in dangerous_imports:
                        if dangerous in line:
                            results['suspicious_imports'].append({
                                'import': line,
                                'module': dangerous
                            })

            # Analyze dangerous functions
            dangerous_functions = [
                'eval(', 'exec(', '__import__(', 'open(',
                'input(', 'raw_input(', 'compile(',
                'globals()', 'locals()', 'vars('
            ]

            for func in dangerous_functions:
                if func in content:
                    results['dangerous_functions'].append(func)

            # Check for hardcoded secrets
            secret_patterns = [
                r'password\s*=\s*["\'][^"\']+["\']',
                r'api_key\s*=\s*["\'][^"\']+["\']',
                r'secret\s*=\s*["\'][^"\']+["\']',
                r'token\s*=\s*["\'][^"\']+["\']',
                r'key\s*=\s*["\'][^"\']+["\']'
            ]

            import re
            for pattern in secret_patterns:
                matches = re.findall(pattern, content, re.IGNORECASE)
                results['hardcoded_secrets'].extend(matches)

            # Code complexity analysis
            results['complexity_score'] = len(lines) + len(results['suspicious_imports']) * 10 + len(results['dangerous_functions']) * 15

        except Exception as e:
            results['error'] = str(e)

        return results

    def behavioral_analysis(self) -> Dict[str, Any]:
        """Analyze potential malicious behavior patterns"""
        results = {
            'network_indicators': [],
            'file_operations': [],
            'system_calls': [],
            'persistence_mechanisms': [],
            'anti_analysis': []
        }

        try:
            with open(self.target_file, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read()

            # Network indicators
            network_patterns = [
                'socket\.', 'connect\(', 'bind\(', 'listen\(',
                'requests\.', 'urllib\.', 'http\.', 'ftp\.',
                '127\.0\.0\.1', 'localhost', '\.onion',
                'pastebin\.com', 'transfer\.sh'
            ]

            for pattern in network_patterns:
                if pattern in content:
                    results['network_indicators'].append(pattern)

            # File operations
            file_patterns = [
                'open\(', 'read\(', 'write\(', 'close\(',
                'os\.remove', 'os\.unlink', 'shutil\.rmtree',
                '/etc/passwd', '/etc/shadow', '~/.ssh',
                'tempfile\.', 'mkstemp', 'mktemp'
            ]

            for pattern in file_patterns:
                if pattern in content:
                    results['file_operations'].append(pattern)

            # System calls
            system_patterns = [
                'subprocess\.', 'os\.system', 'os\.popen',
                'os\.exec', 'os\.spawn', 'commands\.',
                'os\.chmod', 'os\.chown', 'os\.kill'
            ]

            for pattern in system_patterns:
                if pattern in content:
                    results['system_calls'].append(pattern)

            # Persistence mechanisms
            persistence_patterns = [
                'cron', 'systemd', 'rc\.local',
                'bashrc', 'profile', 'autorun',
                'registry', 'startup'
            ]

            for pattern in persistence_patterns:
                if pattern in content:
                    results['persistence_mechanisms'].append(pattern)

            # Anti-analysis techniques
            anti_analysis = [
                'psutil', 'platform', 'getpid',
                'debugger', 'virtual', 'vmware',
                'sandbox', 'analysis'
            ]

            for pattern in anti_analysis:
                if pattern in content:
                    results['anti_analysis'].append(pattern)

        except Exception as e:
            results['error'] = str(e)

        return results

    def dynamic_analysis_simulation(self) -> Dict[str, Any]:
        """Simulate dynamic analysis (safe execution)"""
        results = {
            'execution_simulation': {},
            'resource_usage': {},
            'network_simulation': {},
            'file_simulation': {},
            'warnings': []
        }

        # Simulate execution without actually running
        results['execution_simulation'] = {
            'would_execute': False,
            'reason': 'Sandbox environment - execution disabled for safety',
            'simulated_behavior': 'Code analysis only'
        }

        # Resource usage simulation
        results['resource_usage'] = {
            'cpu_usage': 'Unknown (not executed)',
            'memory_usage': 'Unknown (not executed)',
            'disk_io': 'Unknown (not executed)'
        }

        # Network simulation
        results['network_simulation'] = {
            'connections_attempted': 0,
            'domains_contacted': [],
            'ports_used': []
        }

        # File operations simulation
        results['file_simulation'] = {
            'files_created': [],
            'files_modified': [],
            'files_deleted': []
        }

        results['warnings'] = [
            'Dynamic analysis disabled in demo environment',
            'In production, code would be executed in isolated container',
            'Network calls are blocked for safety',
            'File system access is restricted'
        ]

        return results

    def risk_assessment(self) -> Dict[str, Any]:
        """Calculate overall risk score"""
        static = self.analysis_results.get('static_analysis', {})
        behavioral = self.analysis_results.get('behavioral_analysis', {})

        risk_score = 0

        # Static analysis scoring
        risk_score += len(static.get('suspicious_imports', [])) * 5
        risk_score += len(static.get('dangerous_functions', [])) * 10
        risk_score += len(static.get('hardcoded_secrets', [])) * 15
        risk_score += min(static.get('complexity_score', 0) / 10, 20)

        # Behavioral analysis scoring
        risk_score += len(behavioral.get('network_indicators', [])) * 8
        risk_score += len(behavioral.get('system_calls', [])) * 12
        risk_score += len(behavioral.get('persistence_mechanisms', [])) * 20
        risk_score += len(behavioral.get('anti_analysis', [])) * 15

        # Cap at 100
        risk_score = min(risk_score, 100)

        risk_level = 'Low'
        if risk_score >= 70:
            risk_level = 'High'
        elif risk_score >= 40:
            risk_level = 'Medium'

        return {
            'total_score': risk_score,
            'risk_level': risk_level,
            'confidence': 'High' if risk_score > 50 else 'Medium',
            'factors': {
                'static_analysis_weight': 40,
                'behavioral_analysis_weight': 60
            }
        }

    def generate_recommendations(self) -> List[str]:
        """Generate security recommendations"""
        recommendations = []
        risk_score = self.analysis_results.get('risk_assessment', {}).get('total_score', 0)

        if risk_score >= 70:
            recommendations.extend([
                "ğŸš¨ HIGH RISK: Immediate code review required",
                "Isolate this code in a secure environment",
                "Consider rejecting this code submission",
                "Alert security team immediately"
            ])
        elif risk_score >= 40:
            recommendations.extend([
                "âš ï¸ MEDIUM RISK: Code requires careful review",
                "Test in isolated environment before deployment",
                "Remove any hardcoded credentials",
                "Implement proper input validation"
            ])
        else:
            recommendations.extend([
                "âœ… LOW RISK: Code appears safe",
                "Still perform basic security review",
                "Ensure proper error handling"
            ])

        # Specific recommendations based on findings
        static = self.analysis_results.get('static_analysis', {})
        behavioral = self.analysis_results.get('behavioral_analysis', {})

        if static.get('hardcoded_secrets'):
            recommendations.append("Remove all hardcoded secrets and use environment variables")

        if behavioral.get('network_indicators'):
            recommendations.append("Review all network communications for security")

        if behavioral.get('system_calls'):
            recommendations.append("Audit all system calls for necessity and security")

        return recommendations

    def run_full_analysis(self) -> Dict[str, Any]:
        """Run complete malware analysis"""
        logger.info(f"Starting analysis of {self.target_file}")

        try:
            # File information
            self.analysis_results['file_info'] = self.analyze_file_info()

            # Static analysis
            logger.info("Performing static code analysis...")
            self.analysis_results['static_analysis'] = self.static_code_analysis()

            # Behavioral analysis
            logger.info("Performing behavioral analysis...")
            self.analysis_results['behavioral_analysis'] = self.behavioral_analysis()

            # Dynamic analysis simulation
            logger.info("Performing dynamic analysis simulation...")
            self.analysis_results['dynamic_analysis'] = self.dynamic_analysis_simulation()

            # Risk assessment
            logger.info("Calculating risk assessment...")
            self.analysis_results['risk_assessment'] = self.risk_assessment()

            # Generate recommendations
            self.analysis_results['recommendations'] = self.generate_recommendations()

            # Add metadata
            self.analysis_results['metadata'] = {
                'analysis_start': self.start_time.isoformat(),
                'analysis_end': datetime.now().isoformat(),
                'analyzer_version': '2.0.0',
                'analysis_environment': 'Docker Sandbox'
            }

        except Exception as e:
            logger.error(f"Analysis failed: {e}")
            self.analysis_results['error'] = str(e)

        return self.analysis_results

def main():
    if len(sys.argv) < 2:
        print("Usage: analyze-malware.py <file_to_analyze>")
        sys.exit(1)

    target_file = sys.argv[1]

    if not os.path.exists(target_file):
        print(f"Error: File {target_file} not found")
        sys.exit(1)

    # Run analysis
    analyzer = MalwareAnalyzer(target_file)
    results = analyzer.run_full_analysis()

    # Save results
    output_file = f"{Path(target_file).stem}.analysis.json"
    with open(output_file, 'w') as f:
        json.dump(results, f, indent=2, default=str)

    # Print summary
    risk = results.get('risk_assessment', {})
    print("Malware Analysis Complete")    
    print(f"ğŸ“ File: {target_file}")
    print(f"ğŸ¯ Risk Score: {risk.get('total_score', 0)}/100")
    print(f"ğŸ“Š Risk Level: {risk.get('risk_level', 'Unknown')}")
    print(f"ğŸ’¾ Results saved to: {output_file}")

    # Print key findings
    static = results.get('static_analysis', {})
    behavioral = results.get('behavioral_analysis', {})

    if static.get('hardcoded_secrets'):
        print(f"ğŸ”‘ Found {len(static['hardcoded_secrets'])} potential secrets")

    if behavioral.get('network_indicators'):
        print(f"ğŸŒ Found {len(behavioral['network_indicators'])} network indicators")

    if behavioral.get('system_calls'):
        print(f"âš™ï¸ Found {len(behavioral['system_calls'])} system calls")

if __name__ == '__main__':
    main()